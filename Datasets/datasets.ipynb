{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "import audio_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 40, 4135]), torch.Size([1, 40, 4135]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud00 = torch.rand([1,1323000])\n",
    "aud01 = torch.rand([1,1323001])\n",
    "\n",
    "audio_utils.get_log_melSpectrogram(aud00).shape, audio_utils.get_log_melSpectrogram(aud01).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scraperDataset(Dataset):\n",
    "\n",
    "    '''datadir = '../../audioData/sythenticSoundscenes/test/'\n",
    "    csv = 'scrapper_dataset.csv'''\n",
    "\n",
    "    def __init__(self, dataset_csv, data_dir, only_scene=False):\n",
    "\n",
    "        self.dataset_csv = dataset_csv\n",
    "        self.data_directory = data_dir\n",
    "        self.only_scene = only_scene\n",
    "        self.dataframe = pd.read_csv(dataset_csv)\n",
    "\n",
    "        self.audio_files = self.dataframe['audio_fileNames']\n",
    "        self.label_files = self.dataframe['label_fileNames']\n",
    "        self.scene_labels = self.dataframe['acoustic_scene_label']\n",
    "        self.events_label_list = self.dataframe['events_label_list']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Load Audio file\n",
    "        audio_file = os.path.join(self.data_directory, self.audio_files[idx])\n",
    "        audio_data, sr = torchaudio.load(audio_file)\n",
    "\n",
    "        if self.only_scene:\n",
    "            sample = {'audio':audio_data, 'scene_label':self.scene_labels[idx]}\n",
    "        else:\n",
    "            sample = {'audio':audio_data, 'scene_label':self.scene_labels[idx], 'event_list':self.events_label_list[idx]}\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TUT18_Dataset(Dataset):\n",
    "\n",
    "    '''datadir = '../../audioData/TUTUrban2018/developmentDataset/TUT-urban-acoustic-scenes-2018-development/'\n",
    "    csv = 'TUT18_train.csv'''\n",
    "\n",
    "    def __init__(self, dataset_csv, data_dir):\n",
    "\n",
    "        self.dataset_csv = dataset_csv\n",
    "        self.data_directory = data_dir\n",
    "        self.dataframe = pd.read_csv(dataset_csv)\n",
    "\n",
    "        self.audio_files = self.dataframe['files']\n",
    "        self.scene_labels = self.dataframe['labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        audio_file = os.path.join(self.data_directory, self.audio_files[idx])\n",
    "        audio_data, sr = torchaudio.load(audio_file)\n",
    "\n",
    "        sample = {'audio':audio_data, 'scene_label':self.scene_labels[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '../../audioData/sythenticSoundscenes/test/'\n",
    "#datadir = '../../audioData/TUTUrban2018/developmentDataset/TUT-urban-acoustic-scenes-2018-development/'\n",
    "csv = 'scrapper_test_dataset.csv'\n",
    "#csv = 'TUT18_train.csv'\n",
    "scrapper_df = pd.read_csv(csv)\n",
    "\n",
    "#dataset = scraperDataset(csv, datadir)\n",
    "#dataset = TUT18_Dataset(csv, datadir)\n",
    "\n",
    "#f10 = [dataset[i] for i in range(10)]\n",
    "import re\n",
    "pattern = r'[^a-zA-Z0-9\\s]'\n",
    "event_labels_set = set()\n",
    "\n",
    "for event_list in scrapper_df['events_label_list']:\n",
    "    event_list = re.sub(pattern, '', event_list)\n",
    "    event_labels_set.update(event_list.split(' '))\n",
    "\n",
    "len(event_labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,\n",
       " array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list = []\n",
    "for event_list in scrapper_df['events_label_list']:\n",
    "    event_list = re.sub(pattern, '', event_list)\n",
    "    labels_list.append(event_list.split(' '))\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=list(event_labels_set))\n",
    "one_hot_labes = mlb.fit_transform(labels_list)\n",
    "\n",
    "len(one_hot_labes[0]),one_hot_labes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airport'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f10[2]['scene_label']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noiseremoval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
