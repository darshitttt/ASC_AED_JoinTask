{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "SAMPLE_AUDIO = '/work/dpandya/LibriVox_Kaggle/achtgesichterambiwasse/achtgesichterambiwasse_0007.wav'\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(path, resample=SAMPLE_RATE):\n",
    "    '''\n",
    "    Given a path to the audio file, returns a torch.Tensor array and sampling rate\n",
    "    \n",
    "    Args:\n",
    "    path: The path of the audio file\n",
    "    resample: The resampling rate, if different than default\n",
    "    '''\n",
    "    audio, sr = torchaudio.load(path)\n",
    "    \n",
    "    if (sr==resample):\n",
    "        return audio, sr\n",
    "    else:\n",
    "        resampler = T.Resample(sr, resample, dtype=audio.dtype)\n",
    "        audio = resampler(audio)\n",
    "        return audio, resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_length(audio):\n",
    "    '''\n",
    "    Returns the length of an audio in secs, given the sampling rate is 16000\n",
    "    '''\n",
    "    return len(audio[0])/SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_audio_chunks(audio, chunk_size=1):\n",
    "    '''\n",
    "    This funciton splits audio in chunks of n seconds. \n",
    "    You can adjust the chunk sizes by using chunks_size param\n",
    "\n",
    "    Args:\n",
    "    audio: torch.Tensor of shape [1,n_samples]\n",
    "    chunk_size: desired number of seconds in each chunk\n",
    "\n",
    "    Returns:\n",
    "    audio_chunks: returns a list of audio chunks of the predecided chunk length\n",
    "    '''\n",
    "    t_chunks = chunk_size*SAMPLE_RATE\n",
    "    audio_chunks = []\n",
    "    for i in range(0, len(audio[0]), t_chunks):\n",
    "        audio_chunks.append((audio[0][i:i+t_chunks]).unsqueeze(0))\n",
    "        \n",
    "    return audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/irsolve/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/work/dpandya/miniconda3/envs/irsolve/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                                    use_auth_token=\"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\")\n",
    "\n",
    "\n",
    "# apply the pipeline to an audio file\n",
    "diarization = pipeline(SAMPLE_AUDIO)\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "[tensor([[-1.1451e-04,  5.2144e-05, -1.0690e-04,  ...,  1.8235e-02,\n",
      "          1.9396e-02,  2.0040e-02]]), tensor([[ 0.0197,  0.0181,  0.0145,  ...,  0.0005, -0.0012, -0.0034]]), tensor([[ 0.0031,  0.0037, -0.0005,  ..., -0.0229,  0.0059,  0.0080]]), tensor([[-0.0174,  0.0030,  0.0041,  ..., -0.0371, -0.0422, -0.0455]]), tensor([[-0.0477, -0.0403, -0.0214,  ...,  0.0002,  0.0008,  0.0002]])]\n"
     ]
    }
   ],
   "source": [
    "aud, sr = get_samples(SAMPLE_AUDIO)\n",
    "\n",
    "ll = make_audio_chunks(aud, 2)\n",
    "print(sr)\n",
    "print([i for i in ll])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
